{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3167333,"sourceType":"datasetVersion","datasetId":1887500},{"sourceId":7870364,"sourceType":"datasetVersion","datasetId":4597212}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Context-sensitive Spelling Correction\n\nThe goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n\nSubmit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n\nUseful links:\n- [Norvig's solution](https://norvig.com/spell-correct.html)\n- [Norvig's dataset](https://norvig.com/big.txt)\n- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n\nGrading:\n- 60 points - Implement spelling correction\n- 20 points - Justify your decisions\n- 20 points - Evaluate on a test set\n","metadata":{"id":"DIgM6C9HYUhm"}},{"cell_type":"markdown","source":"## Implement context-sensitive spelling correction\n\nYour task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n\nThe best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n\nYou may also want to implement:\n- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n- some recent (or not very recent) paper on this topic,\n- solution which takes into account keyboard layout and associated misspellings,\n- efficiency improvement to make the solution faster,\n- any other idea of yours to improve the Norvig’s solution.\n\nIMPORTANT:  \nYour project should not be a mere code copy-paste from somewhere. You must provide:\n- Your implementation\n- Analysis of why the implemented approach is suggested\n- Improvements of the original approach that you have chosen to implement","metadata":{"id":"x-vb8yFOGRDF"}},{"cell_type":"markdown","source":"> Implementation of basic class of spelling correction by Norvig","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\nclass SpellCorrector:\n    \"\"\"\n    A class for spelling correction using a simple statistical model based on word frequencies.\n\n    Attributes:\n        counts (Counter): A Counter object containing word frequencies.\n        words_cnt (int): Total count of words in the corpus.\n    \"\"\"\n    def __init__(self, words):\n        \"\"\"\n        Initialize the SpellCorrector object.\n\n        Args:\n            words (list): List of words to build the word frequency counter from.\n        \"\"\"\n        self.counts = Counter(words)\n        self.words_cnt = len(words)\n\n    def correction(self, sentence): \n        \"\"\"\n        Return the most probable spelling correction for a sentence.\n\n        Args:\n            sentence (str): The input sentence to correct.\n        Returns:\n            str: The corrected sentence.\n        \"\"\"\n        return ' '.join([max(self.candidates(word), key=lambda word: self.counts[word] / self.words_cnt) for word in sentence.lower().split()])\n\n    def candidates(self, word):\n        \"\"\"\n        Generate possible spelling corrections for a word.\n\n        Args:\n            word (str): The word to generate corrections for.\n        Returns:\n            set: A set of possible corrections for the word.\n        \"\"\"\n        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])\n\n    def known(self, words):\n        \"\"\"\n        Filter words to get the subset that appear in the dictionary.\n\n        Args:\n            words (list): List of words to filter.\n        Returns:\n            set: A set of words that appear in the dictionary.\n        \"\"\"\n        return set(w for w in words if w in self.counts)\n\n    def edits1(self, word):\n        \"\"\"\n        Generate all edits that are one edit away from a word.\n\n        Args:\n            word (str): The input word.\n        Returns:\n            set: A set of words that are one edit away from the input word.\n        \"\"\"\n        letters    = 'abcdefghijklmnopqrstuvwxyz'\n        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n        deletes    = [L + R[1:]               for L, R in splits if R]\n        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n        replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n        inserts    = [L + c + R               for L, R in splits for c in letters]\n        return set(deletes + transposes + replaces + inserts)\n\n    def edits2(self, word):\n        \"\"\"\n        Generate all edits that are two edits away from a word.\n\n        Args:\n            word (str): The input word.\n        Returns:\n            set: A set of words that are two edits away from the input word.\n        \"\"\"\n        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))\n\n# Small test to ensure that everything works as expected\ntrue_words = [\"spelling\", \"correct\", \"tests\", \"apple\", \"write\", \"process\", 'test']\nspell_corrector = SpellCorrector(true_words)\n\ntest_words = [\"speling\", \"corect\", \"tets\", \"applo\", \"writ\", \"proces\"]\nfor word in test_words:\n    correction = spell_corrector.correction(word)\n    print(f\"{word}, {correction}\")","metadata":{"id":"MoQeEsZvHvvi","execution":{"iopub.status.busy":"2024-03-19T14:05:37.070895Z","iopub.execute_input":"2024-03-19T14:05:37.071342Z","iopub.status.idle":"2024-03-19T14:05:37.144499Z","shell.execute_reply.started":"2024-03-19T14:05:37.071296Z","shell.execute_reply":"2024-03-19T14:05:37.143000Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"speling, spelling\ncorect, correct\ntets, test\napplo, apple\nwrit, write\nproces, process\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> Implementation of spell checker with use of ngram model","metadata":{}},{"cell_type":"code","source":"import itertools\nimport pandas as pd\n\nclass NgramSpellCorrector(SpellCorrector):\n    \"\"\"\n    A class for spelling correction using an n-gram language model.\n\n    Attributes:\n        n (int): The order of the n-gram model.\n        ngram_file_path (str): The file path to the n-gram data.\n        ngrams (dict): A dictionary containing n-grams as keys and their frequencies as values.\n        counts (dict): A dictionary containing word frequencies.\n    \"\"\"\n    def __init__(self, n=2, ngram_file_path='/kaggle/input/nlp-a2/bigrams.txt'):\n        \"\"\"\n        Initialize the NgramSpellCorrector object.\n\n        Args:\n            n (int): The order of the n-gram model. Defaults to 2.\n            ngram_file_path (str): The file path to the n-gram data. Defaults to '/kaggle/input/nlp-a2/bigrams.txt'.\n        \"\"\"\n        ngrams = pd.read_csv(ngram_file_path, sep='\\t', encoding='latin-1', header=None)\n        self.ngrams = dict()\n        self.counts = dict()\n        self.n = n\n        for items in ngrams.itertuples():\n            key = tuple(items[i] for i in range(2, n + 2))\n            self.ngrams[key] = int(items[1])\n            for k in key:\n                if k not in self.counts:\n                    self.counts[k] = 0\n                self.counts[k] += 1\n        self.words_cnt = sum(self.ngrams.values())\n        super().__init__(self.counts.keys())\n    \n    def correction(self, sentence):\n        \"\"\"\n        Return the most probable spelling correction for a sentence using n-gram language model.\n\n        Args:\n            sentence (str): The input sentence to correct.\n        Returns:\n            str: The corrected sentence.\n        \"\"\"\n        def P(x):\n            if x not in self.ngrams:\n                return 1 / (self.words_cnt + 2)\n            return (self.ngrams[x] + 1) / (self.words_cnt + 2)\n        \n        words = sentence.lower().split(' ')\n        candidates = []\n        for word in words:\n            if len(self.known([word])) == 1:\n                candidates += [[word]]\n                continue\n            candidates += [self.candidates(word)]\n        corrected = []\n        combinations = list(itertools.product(*(candidates[i] for i in range(min(len(candidates), self.n)))))\n        combinations.sort(key=P)\n        corrected += [combinations[-1][i] for i in range(min(self.n, len(candidates)))]\n        for i in range(self.n, len(candidates)):\n            combinations = list(itertools.product([corrected[-1]], candidates[i]))\n            combinations.sort(key=P)\n            corrected += [combinations[-1][1]]\n        return ' '.join(corrected)\n    \n    def candidates(self, word):\n        \"\"\"\n        Generate possible spelling corrections for a word using n-gram language model.\n\n        Args:\n            word (str): The word to generate corrections for.\n        Returns:\n            set: A set of possible corrections for the word.\n        \"\"\"\n        return (self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])\n    \n    def known(self, words):\n        \"\"\"\n        Filter words to get the subset that appear in the dictionary.\n\n        Args:\n            words (list): List of words to filter.\n        Returns:\n            set: A set of words that appear in the dictionary.\n        \"\"\"\n        return set(w for w in words if w in self.counts)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T14:05:38.290832Z","iopub.execute_input":"2024-03-19T14:05:38.291293Z","iopub.status.idle":"2024-03-19T14:05:38.833088Z","shell.execute_reply.started":"2024-03-19T14:05:38.291258Z","shell.execute_reply":"2024-03-19T14:05:38.831813Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Instance that utilize bigrams\nbigram_corrector = NgramSpellCorrector()\n\n# Moreover, I tested with 3-grams and 5-grams, but it has lower performance. I will show it in testing section\n\n# corrector = NgramSpellCorrector(ngram_file_path='/kaggle/input/nlp-a2/wp_2gram.txt')\n# corrector = NgramSpellCorrector(ngram_file_path='/kaggle/input/nlp-a2/coca_all_links.txt', n=3)\n# corrector = NgramSpellCorrector(ngram_file_path='/kaggle/input/nlp-a2/fivegrams.txt', n=5)","metadata":{"execution":{"iopub.status.busy":"2024-03-19T14:05:40.452546Z","iopub.execute_input":"2024-03-19T14:05:40.453939Z","iopub.status.idle":"2024-03-19T14:05:46.548763Z","shell.execute_reply.started":"2024-03-19T14:05:40.453898Z","shell.execute_reply":"2024-03-19T14:05:46.547490Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"> Small test to ensure that it's working","metadata":{}},{"cell_type":"code","source":"print(bigram_corrector.correction('wriqe biologyh expm'))\nprint(bigram_corrector.correction('I am goinq to killl all my enemes in gamee'))\nprint(bigram_corrector.correction('what a dog doin'))\nprint(bigram_corrector.correction('doing mth cooking mth telling mth'))","metadata":{"execution":{"iopub.status.busy":"2024-03-19T14:05:47.100790Z","iopub.execute_input":"2024-03-19T14:05:47.101271Z","iopub.status.idle":"2024-03-19T14:05:47.112024Z","shell.execute_reply.started":"2024-03-19T14:05:47.101232Z","shell.execute_reply":"2024-03-19T14:05:47.110081Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"write biology expo\ni am going to kill all my enemies in game\nwhat a dog doin\ndoing math cooking th telling th\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Justify your decisions\n\nWrite down justificaitons for your implementation choices. For example, these choices could be:\n- Which ngram dataset to use\n- Which weights to assign for edit1, edit2 or absent words probabilities\n- Beam search parameters\n- etc.","metadata":{"id":"oML-5sJwGRLE"}},{"cell_type":"markdown","source":"### Justifications for Implementation Choices:\n\n1. **N-gram Dataset Selection**:\n   - I utilized the provided n-gram dataset `bigrams.txt`. This dataset was chosen because it provides the necessary n-gram frequencies required for building the language model. Moreover, I tried the Wikipedia Bigrams dataset, but it performed poorly. Therefore, I opted to stick with `bigrams.txt`.\n\n\n2. **Word Skip**:\n   - If a word is known by the spell checker, it will be skipped because it is already correctly spelled. We don't want to fix words that are correct according to their frequency.\n\n\n3. **Incorporation of Laplace Smoothing**:\n   - Laplace smoothing (add-one smoothing) was employed in computing n-gram probabilities to handle unseen n-grams in the dataset. This helps avoid zero probabilities for unseen n-grams and ensures that every n-gram has a non-zero probability.\n\n\n4. **Beam Search Parameters**:\n   - Beam search is not explicitly utilized. However, a form of beam search is implicitly performed when selecting the most probable correction for each word. Instead of exhaustively considering all possible combinations of corrections, I considered a subset of the most probable corrections based on the n-gram probabilities. This approach reduces computational complexity while still aiming to find a reasonable correction for the input sentence.","metadata":{"id":"6Xb_twOmVsC6"}},{"cell_type":"markdown","source":"## Evaluate on a test set\n\nYour task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies.","metadata":{"id":"46rk65S4GRSe"}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/spelling-mistake-data-1mn/test.csv')\ntest_df.head()","metadata":{"id":"OwZWaX9VVs7B","execution":{"iopub.status.busy":"2024-03-19T14:05:49.466071Z","iopub.execute_input":"2024-03-19T14:05:49.466448Z","iopub.status.idle":"2024-03-19T14:05:49.843526Z","shell.execute_reply.started":"2024-03-19T14:05:49.466418Z","shell.execute_reply":"2024-03-19T14:05:49.842262Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text  \\\n0      project looks to mulesing genetic alternative   \n1  chemical agents used during protest at port au...   \n2  business chamber seeks budget infrastructure b...   \n3        3600 trips made to darwin tip after cyclone   \n4                   go between bridge to open july 5   \n\n                                      augmented_text  \n0      project looks to muelsnig ngeetic alternative  \n1  chemical agents used during LrotWst at port ah...  \n2  business hcmaber seeks budget infrastrcutuer b...  \n3        3600 trips made to adrwni tip after cyconle  \n4                   go net3een brisye to lprn july 5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>augmented_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>project looks to mulesing genetic alternative</td>\n      <td>project looks to muelsnig ngeetic alternative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>chemical agents used during protest at port au...</td>\n      <td>chemical agents used during LrotWst at port ah...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>business chamber seeks budget infrastructure b...</td>\n      <td>business hcmaber seeks budget infrastrcutuer b...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3600 trips made to darwin tip after cyclone</td>\n      <td>3600 trips made to adrwni tip after cyconle</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>go between bridge to open july 5</td>\n      <td>go net3een brisye to lprn july 5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef evaluate_correction(corrector, test_df, size=100):\n    total_words = 0\n    correct_words = 0\n    total_sentences = 0\n    correct_sentences = 0\n    \n    size = min(size, len(test_df))\n    bar = tqdm(test_df[:size].iterrows(), total=size)\n    for index, row in bar:\n        original_text = row['text']\n        augmented_text = row['augmented_text']\n        corrected_text = corrector.correction(augmented_text)\n        \n        original_words = original_text.split()\n        augmented_words = augmented_text.split()\n        corrected_words = corrected_text.split()\n        \n#         total_words += len(original_words)\n        total_words += sum(1 for orig, aug in zip(original_words, augmented_words) if orig != aug)\n        total_sentences += 1\n        \n        if original_words == corrected_words:\n            correct_words += len(original_words)\n            correct_sentences += 1\n        else:\n            correct_words += sum(1 for orig, aug, corr in zip(original_words, augmented_words, corrected_words) if orig == corr and orig != aug)\n    \n    word_accuracy = correct_words / total_words if total_words > 0 else 0\n    sentence_accuracy = correct_sentences / total_sentences if total_sentences > 0 else 0\n    \n    return word_accuracy, sentence_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-03-19T14:05:50.667071Z","iopub.execute_input":"2024-03-19T14:05:50.667934Z","iopub.status.idle":"2024-03-19T14:05:50.687353Z","shell.execute_reply.started":"2024-03-19T14:05:50.667895Z","shell.execute_reply":"2024-03-19T14:05:50.686117Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"words = []\nfor word in bigram_corrector.counts.keys():\n    for i in range(bigram_corrector.counts[word]):\n        words.append(word)\n\ncorrectors = [(SpellCorrector(words), 'Norvig'), (bigram_corrector, 'Bigrams basic'), \n              (NgramSpellCorrector(ngram_file_path='/kaggle/input/nlp-a2/wp_2gram.txt'), 'Bigrams Wiki'),\n              (NgramSpellCorrector(ngram_file_path='/kaggle/input/nlp-a2/coca_all_links.txt'), 'Trigrams'),\n              (NgramSpellCorrector(ngram_file_path='/kaggle/input/nlp-a2/fivegrams.txt'), 'Fivegrams')]","metadata":{"execution":{"iopub.status.busy":"2024-03-19T14:06:07.176721Z","iopub.execute_input":"2024-03-19T14:06:07.177184Z","iopub.status.idle":"2024-03-19T14:11:37.230890Z","shell.execute_reply.started":"2024-03-19T14:06:07.177146Z","shell.execute_reply":"2024-03-19T14:11:37.229327Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for corrector, name in correctors:\n    word_accuracy, sentence_accuracy = evaluate_correction(corrector, test_df, size=500)\n    print(f\"Metrics for '{name}'\")\n    print(\"\\tWord Accuracy:\", word_accuracy)\n    print(\"\\tSentence Accuracy:\", sentence_accuracy)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-03-19T14:19:28.886272Z","iopub.execute_input":"2024-03-19T14:19:28.887657Z","iopub.status.idle":"2024-03-19T14:30:34.724758Z","shell.execute_reply.started":"2024-03-19T14:19:28.887543Z","shell.execute_reply":"2024-03-19T14:30:34.723250Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 500/500 [02:09<00:00,  3.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Metrics for 'Norvig'\n\tWord Accuracy: 0.5463917525773195\n\tSentence Accuracy: 0.116\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 500/500 [02:07<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Metrics for 'Bigrams basic'\n\tWord Accuracy: 0.6708961141950832\n\tSentence Accuracy: 0.13\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 500/500 [01:51<00:00,  4.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Metrics for 'Bigrams Wiki'\n\tWord Accuracy: 0.3203806502775575\n\tSentence Accuracy: 0.058\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 500/500 [02:33<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Metrics for 'Trigrams'\n\tWord Accuracy: 0.36082474226804123\n\tSentence Accuracy: 0.014\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 500/500 [02:24<00:00,  3.47it/s]","output_type":"stream"},{"name":"stdout","text":"Metrics for 'Fivegrams'\n\tWord Accuracy: 0.49246629659000796\n\tSentence Accuracy: 0.066\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Bigram perform better others.","metadata":{}}]}